---

# The chart to use
kube_prometheus_stack_chart_repo: https://prometheus-community.github.io/helm-charts
kube_prometheus_stack_chart_name: kube-prometheus-stack
kube_prometheus_stack_chart_version: 59.1.0

# Release information
kube_prometheus_stack_release_namespace: monitoring-system
kube_prometheus_stack_release_name: kube-prometheus-stack

# The timeout to wait for the release to become ready
kube_prometheus_stack_wait_timeout: 5m

login_ip: "{{ hostvars[groups['openondemand'][0]]['ansible_host'] }}" # probably needs to be more robust
control_ip: "{{ ansible_default_ipv4.address| default(ansible_all_ipv4_addresses[0]) }}"
control_sslip: "{{ control_ip | regex_replace('\\.', '-') }}.sslip.io" 

grafana_claim_size: 10Gi

grafana_anonymous_auth: true

slack_integration:
  channel: "#alerts"
  app_creds: # TODO: need to find best way to build this into secrets store as must be manually retrieved from app

alertmanager_config:
  route:
    group_by: ['...']
    receiver: slack-receiver
  global:
    resolve_timeout: "{{ prometheus_config_flags_extra.alertmanager.timeout | default( '5m' ) }}"
  receivers:
    - name: 'null'
    - name: slack-receiver
      slack_configs:
        - channel: "{{ slack_integration.channel }}"
          api_url: https://slack.com/api/chat.postMessage
          http_config:
            authorization:
              credentials: "{{ slack_integration.app_creds }}"
          text: "{{ '{{' }} .GroupLabels.alertname {{ '}}' }} : {{ '{{' }}  .CommonAnnotations.description {{ '}}' }}"
          title_link: "http://{{ control_ip }}/alertmanager/#/alerts?receiver=slack-receiver"

### PREVIOUS ROLE VALUES

prometheus_image_tag: "v2.27.0"

# prometheus_config_dir: /etc/prometheus
prometheus_db_dir: "{{ appliances_state_dir }}/prometheus"
# prometheus_read_only_dirs: []

# prometheus_binary_local_dir: ''
# prometheus_skip_install: false

# prometheus_web_listen_address: "0.0.0.0:9090"
# prometheus_web_external_url: ''
# See https://github.com/prometheus/exporter-toolkit/blob/master/docs/web-configuration.md
# prometheus_web_config:
#   tls_server_config: {}
#   http_server_config: {}
#   basic_auth_users: {}

prometheus_storage_retention: "30d"
# Available since Prometheus 2.7.0
# [EXPERIMENTAL] Maximum number of bytes that can be stored for blocks. Units
# supported: KB, MB, GB, TB, PB.
prometheus_storage_retention_size: "40GB"

kube_prometheus_stack_volume_size: 40Gi

prometheus_config_flags_extra: {}
# prometheus_config_flags_extra:
#   storage.tsdb.retention: 15d
#   alertmanager.timeout: 10s

prometheus_alertmanager_config: []
# prometheus_alertmanager_config:
#   - scheme: https
#     path_prefix: alertmanager/
#     basic_auth:
#       username: user
#       password: pass
#     static_configs:
#       - targets: ["127.0.0.1:9093"]
#     proxy_url: "127.0.0.2"

prometheus_alert_relabel_configs: []
# prometheus_alert_relabel_configs:
#   - action: labeldrop
#     regex: replica

prometheus_global:
  scrape_interval: 15s
  scrape_timeout: 10s
  evaluation_interval: 15s

prometheus_remote_write: []
# prometheus_remote_write:
#   - url: https://dev.kausal.co/prom/push
#     basic_auth:
#       password: FOO

prometheus_remote_read: []
# prometheus_remote_read:
#   - url: https://demo.cloudalchemy.org:9201/read
#     basic_auth:
#       password: FOO

prometheus_external_labels:
  environment: "{{ ansible_fqdn | default(ansible_host) | default(inventory_hostname) }}"
  # environment: "{{ control_sslip }}"

prometheus_targets: {}
#  node:
#    - targets:
#        - localhost:9100
#      labels:
#        env: test

prometheus_scrape_configs:
  - job_name: "slurm_exporter"
    scrape_interval: 30s
    scrape_timeout: 30s
    static_configs:
      - targets:
        - "{{ control_ip }}:{{ slurm_exporter_port }}"
  - job_name: "grafana"
    static_configs:
    - targets:
      - "kube-prometheus-stack-grafana:{{ grafana_port }}"

# Alternative config file name, searched in ansible templates path.
# prometheus_config_file: 'prometheus.yml.j2'

# prometheus_alert_rules_files:
#   - prometheus/rules/*.rules

# prometheus_static_targets_files:
#   - prometheus/targets/*.yml
#   - prometheus/targets/*.json

prometheus_alert_rules:
  - alert: Watchdog
    expr: vector(1)
    for: 10m
    labels:
      severity: warning
    annotations:
      description: "This is an alert meant to ensure that the entire alerting pipeline is functional.\nThis alert is always firing, therefore it should always be firing in Alertmanager\nand always fire against a receiver. There are integrations with various notification\nmechanisms that send a notification when this alert is not firing. For example the\n\"DeadMansSnitch\" integration in PagerDuty."
      summary: 'Ensure entire alerting pipeline is functional'
  - alert: InstanceDown
    expr: 'up == 0'
    for: 5m
    labels:
      severity: critical
    annotations:
      description: '{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.{% endraw %}'
      summary: '{% raw %}Instance {{ $labels.instance }} down{% endraw %}'
  - alert: RebootRequired
    expr: 'node_reboot_required > 0'
    labels:
      severity: warning
    annotations:
      description: '{% raw %}{{ $labels.instance }} requires a reboot.{% endraw %}'
      summary: '{% raw %}Instance {{ $labels.instance }} - reboot required{% endraw %}'
  - alert: NodeFilesystemSpaceFillingUp
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left and is filling up.{% endraw %}'
      summary: 'Filesystem is predicted to run out of space within the next 24 hours.'
    expr: "(\n  node_filesystem_avail_bytes{job=\"node\",fstype!=\"\"} / node_filesystem_size_bytes{job=\"node\",fstype!=\"\"} * 100 < 40\nand\n  predict_linear(node_filesystem_avail_bytes{job=\"node\",fstype!=\"\"}[6h], 24*60*60) < 0\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: warning
  - alert: NodeFilesystemSpaceFillingUp
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left and is filling up fast.{% endraw %}'
      summary: 'Filesystem is predicted to run out of space within the next 4 hours.'
    expr: "(\n  node_filesystem_avail_bytes{job=\"node\",fstype!=\"\"} / node_filesystem_size_bytes{job=\"node\",fstype!=\"\"} * 100 < 20\nand\n  predict_linear(node_filesystem_avail_bytes{job=\"node\",fstype!=\"\"}[6h], 4*60*60) < 0\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: critical
  - alert: NodeFilesystemAlmostOutOfSpace
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left.{% endraw %}'
      summary: 'Filesystem has less than 5% space left.'
    expr: "(\n  node_filesystem_avail_bytes{job=\"node\",fstype!=\"\"} / node_filesystem_size_bytes{job=\"node\",fstype!=\"\"} * 100 < 5\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: warning
  - alert: NodeFilesystemAlmostOutOfSpace
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left.{% endraw %}'
      summary: 'Filesystem has less than 3% space left.'
    expr: "(\n  node_filesystem_avail_bytes{job=\"node\",fstype!=\"\"} / node_filesystem_size_bytes{job=\"node\",fstype!=\"\"} * 100 < 3\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: critical
  - alert: NodeFilesystemFilesFillingUp
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left and is filling up.{% endraw %}'
      summary: 'Filesystem is predicted to run out of inodes within the next 24 hours.'
    expr: "(\n  node_filesystem_files_free{job=\"node\",fstype!=\"\"} / node_filesystem_files{job=\"node\",fstype!=\"\"} * 100 < 40\nand\n  predict_linear(node_filesystem_files_free{job=\"node\",fstype!=\"\"}[6h], 24*60*60) < 0\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: warning
  - alert: NodeFilesystemFilesFillingUp
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left and is filling up fast.{% endraw %}'
      summary: 'Filesystem is predicted to run out of inodes within the next 4 hours.'
    expr: "(\n  node_filesystem_files_free{job=\"node\",fstype!=\"\"} / node_filesystem_files{job=\"node\",fstype!=\"\"} * 100 < 20\nand\n  predict_linear(node_filesystem_files_free{job=\"node\",fstype!=\"\"}[6h], 4*60*60) < 0\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: critical
  - alert: NodeFilesystemAlmostOutOfFiles
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left.{% endraw %}'
      summary: 'Filesystem has less than 5% inodes left.'
    expr: "(\n  node_filesystem_files_free{job=\"node\",fstype!=\"\"} / node_filesystem_files{job=\"node\",fstype!=\"\"} * 100 < 5\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: warning
  - alert: NodeFilesystemAlmostOutOfFiles
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left.{% endraw %}'
      summary: 'Filesystem has less than 3% inodes left.'
    expr: "(\n  node_filesystem_files_free{job=\"node\",fstype!=\"\"} / node_filesystem_files{job=\"node\",fstype!=\"\"} * 100 < 3\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: critical
  - alert: NodeNetworkReceiveErrs
    annotations:
      description: '{% raw %}{{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf "%.0f" $value }} receive errors in the last two minutes.{% endraw %}'
      summary: 'Network interface is reporting many receive errors.'
    expr: "increase(node_network_receive_errs_total[2m]) > 10\n"
    for: 1h
    labels:
      severity: warning
  - alert: NodeNetworkTransmitErrs
    annotations:
      description: '{% raw %}{{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf "%.0f" $value }} transmit errors in the last two minutes.{% endraw %}'
      summary: 'Network interface is reporting many transmit errors.'
    expr: "increase(node_network_transmit_errs_total[2m]) > 10\n"
    for: 1h
    labels:
      severity: warning
  - alert: NodeHighNumberConntrackEntriesUsed
    annotations:
      description: '{% raw %}{{ $value | humanizePercentage }} of conntrack entries are used{% endraw %}'
      summary: 'Number of conntrack are getting close to the limit'
    expr: "(node_nf_conntrack_entries / node_nf_conntrack_entries_limit) > 0.75\n"
    labels:
      severity: warning
  - alert: NodeClockSkewDetected
    annotations:
      message: '{% raw %}Clock on {{ $labels.instance }} is out of sync by more than 300s. Ensure NTP is configured correctly on this host.{% endraw %}'
      summary: 'Clock skew detected.'
    expr: "(\n  node_timex_offset_seconds > 0.05\nand\n  deriv(node_timex_offset_seconds[5m]) >= 0\n)\nor\n(\n  node_timex_offset_seconds < -0.05\nand\n  deriv(node_timex_offset_seconds[5m]) <= 0\n)\n"
    for: 10m
    labels:
      severity: warning
  - alert: NodeClockNotSynchronising
    annotations:
      message: '{% raw %}Clock on {{ $labels.instance }} is not synchronising. Ensure NTP is configured on this host.{% endraw %}'
      summary: 'Clock not synchronising.'
    expr: "min_over_time(node_timex_sync_status[5m]) == 0\n"
    for: 10m
    labels:
      severity: warning

# ------------------------------------------------------------------------------------------

### PREVIOUS GRAFANA VARS
grafana_image_tag: 11.2.2

grafana_instance: "{{ ansible_fqdn | default(ansible_host) | default(inventory_hostname) }}"

grafana_data_dir: "/var/lib/grafana"

grafana_port: 80

# Additional options for grafana "server" section
# This section WILL omit options for: http_addr, http_port, domain, and root_url, as those settings are set by variables listed before
# grafana_server:
#   protocol: http
#   enforce_domain: false
#   socket: ""
#   cert_key: ""
#   cert_file: ""
#   enable_gzip: false
#   static_root_path: public
#   router_logging: false
#   serve_from_sub_path: false

# # Variables correspond to ones in grafana.ini configuration file
# # Security
# grafana_security:
#   admin_user: admin
#   admin_password: ""
# #  secret_key: ""
# #  login_remember_days: 7
# #  cookie_username: grafana_user
# #  cookie_remember_name: grafana_remember
# #  disable_gravatar: true
# #  data_source_proxy_whitelist:

# User management and registration
# grafana_welcome_email_on_sign_up: false
# grafana_users:
#   allow_sign_up: false
#   # allow_org_create: true
#   # auto_assign_org: true
#   auto_assign_org_role: Viewer
#   # login_hint: "email or username"
#   default_theme: dark
#   # external_manage_link_url: ""
#   # external_manage_link_name: ""
#   # external_manage_info: ""

# grafana authentication mechanisms
grafana_auth: {}
#  disable_login_form: false
#  oauth_auto_login: false
#  disable_signout_menu: false
#  signout_redirect_url: ""
#  ldap:
#    config_file: "/etc/grafana/ldap.toml"
#    allow_sign_up: false
#  basic:
#    enabled: true

grafana_ldap: {}
#  verbose_logging: false
#  servers:
#    host: 127.0.0.1
#    port: 389 # 636 for SSL
#    use_ssl: false
#    start_tls: false
#    ssl_skip_verify: false
#    root_ca_cert: /path/to/certificate.crt
#    bind_dn: "cn=admin,dc=grafana,dc=org"
#    bind_password: grafana
#    search_filter: "(cn=%s)" # "(sAMAccountName=%s)" on AD
#    search_base_dns:
#      - "dc=grafana,dc=org"
#    group_search_filter: "(&(objectClass=posixGroup)(memberUid=%s))"
#    group_search_base_dns:
#      - "ou=groups,dc=grafana,dc=org"
#    attributes:
#      name: givenName
#      surname: sn
#      username: sAMAccountName
#      member_of: memberOf
#      email: mail
#  group_mappings:
#    - name: Main Org.
#      id: 1
#      groups:
#        - group_dn: "cn=admins,ou=groups,dc=grafana,dc=org"
#          org_role: Admin
#        - group_dn: "cn=editors,ou=groups,dc=grafana,dc=org"
#          org_role: Editor
#        - group_dn: "*"
#          org_role: Viewer
#    - name: Alternative Org
#      id: 2
#      groups:
#        - group_dn: "cn=alternative_admins,ou=groups,dc=grafana,dc=org"
#          org_role: Admin

grafana_analytics: {}
#  reporting_enabled: true
#  google_analytics_ua_id: ""

# Set this for mail notifications
grafana_smtp: {}
#  host:
#  user:
#  password:
#  from_address:

# Grafana logging configuration
grafana_log:
# mode: 'console file'
# level: info

# Distributed tracing options
grafana_tracing: {}
#  address: "localhost:6831"
#  always_included_tag: "tag1:value1,tag2:value2"
#  sampler_type: const
#  sampler_param: 1

grafana_snapshots: {}
#  external_enabled: true
#  external_snapshot_url: "https://snapshots-origin.raintank.io"
#  external_snapshot_name: "Publish to snapshot.raintank.io"
#  snapshot_remove_expired: true
#  snapshot_TTL_days: 90

# # External image store
# grafana_image_storage: {}
# #  provider: gcs
# #  key_file:
# #  bucket:
# #  path:


#######
# Plugins from https://grafana.com/plugins
grafana_plugins: []
#  - raintank-worldping-app

# # Dashboards from https://grafana.com/dashboards
# grafana_dashboards: []
# #  - dashboard_id: '4271'
# #    revision_id: '3'
# #    datasource: 'Prometheus'
# #  - dashboard_id: '1860'
# #    revision_id: '4'
# #    datasource: 'Prometheus'
# #  - dashboard_id: '358'
# #    revision_id: '1'
# #    datasource: 'Prometheus'

# grafana_dashboards_dir: "dashboards"

# # Alert notification channels to configure
# grafana_alert_notifications: []
# #  - name: "Email Alert"
# #    type: "email"
# #    uid: channel1
# #    is_default: true
# #    settings:
# #      addresses: "example@example.com"

# Datasources to configure
grafana_datasources: []
#  - name: "Prometheus"
#    type: "prometheus"
#    access: "proxy"
#    url: "http://prometheus.mydomain"
#    basicAuth: true
#    basicAuthUser: "admin"
#    basicAuthPassword: "password"
#    isDefault: true
#    jsonData:
#      tlsAuth: false
#      tlsAuthWithCACert: false
#      tlsSkipVerify: true

grafana_environment: {}

# Panels configurations
grafana_panels: {}
#  disable_sanitize_html: false
#  enable_alpha: false

