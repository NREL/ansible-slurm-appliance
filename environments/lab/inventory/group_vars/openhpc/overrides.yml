

openhpc_slurm_partitions:
  - name: "sm"
    default: NO
    maxtime: "1-0" # 1 days 0 hours
  - name: "ty"
    default: YES
    maxtime: "1-0" # 1 days 0 hours

# Additional parameters to set in slurm.conf - list of [parameter, value] pairs
openhpc_config_extra:
  LaunchParameters: use_interactive_step
  FirstJobId: '50000000'
  PropagateResourceLimits: 'NONE'
  # vs cgid
  # ProctrackType: proctrack/cgroup
  ReturnToService: '1'
  SlurmctldPidFile: /var/run/slurmctld.pid
  SlurmdPidFile: /var/run/slurmd.pid
  SlurmdSpoolDir: /var/spool/slurm/slurmd
  StateSaveLocation: /var/spool/slurm/slurmctld
  SwitchType: 'switch/none'
  TaskPlugin: 'task/affinity'
  #- TaskPlugin: 'task/affinity,task/cgroup'

  # Use sbatch or srun, however...
  # Don't recomend salloc, but this makes it less troublesome
  #### This fails kbendl - 2021-07-05
  # - SallocDefaultCommand: 'srun  --pty --gres=NONE --preserve-env $SHELL'

  # PROLOGUE & EPILOGUE
  # - JobSubmitPlugins: 'require_timelimit,lua'
  # - PrologSlurmctld: '/nopt/slurm/etc/prologslurmctld.sh'
  # - Prolog: '/nopt/slurm/etc/prolog.d/*'
  # - PrologFlags: 'X11'
  # - X11Parameters: 'local_xauthority'
  # - Epilog: '/nopt/slurm/etc/epilog.d/*'
  # - PrologEpilogTimeout: 180
  # - UnkillableStepTimeout: 180

  # FairShare/FairTree Halflife decay, starting at 14 days on Oct 5th 2020:
  - PriorityDecayHalfLife: '14-0'

  # PRIORITY
  # WHB on 2021-05-03 ref: HPCOPS-1447
  # to rebalance things to give a small (4%) weight to job age:
  #   fairshare 52%
  #   QoS 27%
  #   jobsize 12%
  #   partition = 5%
  #   Age 4%

  - PriorityType: 'priority/multifactor'
  - PriorityMaxAge: '14-0'
  - PriorityWeightFairshare: '397659600'
  - PriorityWeightAge: '30589200'
  - PriorityWeightJobSize: '91767600'
  - PriorityWeightQOS: '206477100'
  - PriorityWeightPartition: '38236500'

  # TIMERS  size because db on spinning disk so had to increase
  - BatchStartTimeout: '30'
  - MessageTimeout: '100'
  - TCPTimeout: '10'

  # SCHEDULING
  - SchedulerType: 'sched/backfill'
  - SelectType: 'select/cons_res'
  - SelectTypeParameters: 'CR_Core'
  - EnforcePartLimits: 'ALL'
  - SchedulerParameters:
    - defer
    - default_queue_depth=10750
    - max_rpc_cnt=125
    - max_sched_time=6
    - partition_job_depth=10500
    - sched_max_job_start=200
    - sched_min_interval=2000000
    - batch_sched_delay=20
    - bf_max_job_test=13000
    - bf_interval=30
    - bf_continue
    - bf_window=15840
    - bf_resolution=250
    - max_switch_wait=172800
  #FastSchedule=1

# LOGGING
# Silence warnings about configuration file mismatches. TODO: ask why required?
  - DebugFlags: 'NO_CONF_HASH'
  - SlurmctldDebug: 'info'
  - SlurmctldLogFile: '/var/log/slurmctld.log'
  - SlurmdDebug: 'info'
  - JobCompType: 'jobcomp/none'
  - JobCompLoc: '/var/log/slurm_jobacct.log'
#SlurmdLogFile=

# ACCOUNTING
### start with a qos
  - AccountingStorageEnforce:
    - safe
    - qos
    - limits
  - AcctGatherNodeFreq: '30'
  - AccountingStorageTRES: 'gres/gpu'

## added kmb
  - AccountingStorageHost: 'vs-control'
  - AccountingStorageUser: 'slurm'
  - AccountingStorageType: 'accounting_storage/slurmdbd'
  - AcctGatherFilesystemType: 'acct_gather_filesystem/lustre'

#  - JobAcctGatherType: 'jobacct_gather/linux'
#  - JobAcctGatherParams: 'UsePss'
#  - JobAcctGatherFrequency: 'task=30,energy=30'

# kbendl - the ephemeral mount for SSD?
  - TmpFS: '/var/scratch'
  - GresTypes: 'gpu'
  ### - MpiDefault: "pmi2"    ### get the launcher to work! pmi1, pmi2, or pmix
  # # spack mpi drivers were a mis-match... is this working now????

  # # NREL: see topology.conf
  # - 'TopologyPlugin: 'topology/tree'
  # - 'JobRequeue: 0
  # - 'MaxJobCount: 40000

  ### NREL:
  # Kurt... Need to build this - may need the mellanox info here.
  #NHC Node Health Check
  # - HealthCheckProgram: '/usr/sbin/nhc'
  # - HealthCheckInterval: 300
  # - HealthCheckNodeState: 'CYCLE,ANY'
