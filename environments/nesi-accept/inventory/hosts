[all:vars]
ansible_user=centos
openhpc_cluster_name=accept

# --- hosts below taken from kayobe-config/etc/kayobe/inventory/overcloud but named for slurm appliance ---

[accept_ceph_hdd]
# disabled due to firmware upgrade issues
#a01ss01 ipmi_address=10.110.113.151 bmc_type=
#a01ss02 ipmi_address=10.110.113.152 bmc_type=
#a01ss03 ipmi_address=10.110.113.153 bmc_type=
#a01ss04 ipmi_address=10.110.113.154 bmc_type=
#a01ss05 ipmi_address=10.110.113.155 bmc_type=
#a01ss06 ipmi_address=10.110.113.156 bmc_type=

[accept_ceph_ssd]
a01fs01 ipmi_address=10.110.113.102 bmc_type=
a01fs02 ipmi_address=10.110.113.101 bmc_type=

[accept_compute] # NB had to change name here!
a01co01 ipmi_address=10.110.113.1 bmc_type=
a01co02 ipmi_address=10.110.113.2 bmc_type=
a01co03 ipmi_address=10.110.113.3 bmc_type=
a01co04 ipmi_address=10.110.113.4 bmc_type=

[accept_controllers]
a01cc01 ipmi_address=10.110.113.201 bmc_type=
a01cc02 ipmi_address=10.110.113.202 bmc_type=
a01cc03 ipmi_address=10.110.113.203 bmc_type=

# --- normal slurm appliance hosts ---

[control]
# reuse first "control" host as slurm control node too
#a01cc01
# use first "compute" while control broken
a01co01

#[login]
# Not defined as using combined control/compute/login node

[compute:children]
#accept_ceph_hdd
accept_ceph_ssd
accept_compute
accept_controllers
